{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metagenomic_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RRdnF-T7GW3A",
        "SsYlsw4_Gbcc",
        "143wOQzGFQlL"
      ],
      "mount_file_id": "1fL0-eDKgqVA4MlRSci89QiN6Bhk3Uyol",
      "authorship_tag": "ABX9TyMFHiLbD7iI5n5zqOW+c9N0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xelanac/metagenomic-project/blob/main/metagenomic_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AruxVWPFnO"
      },
      "source": [
        "#Import delle librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDP2iYK4O-X6"
      },
      "source": [
        "%%capture\n",
        "!pip3 install google-nucleus==0.4.0\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#librerie per la lettura dei file fastq\n",
        "from nucleus.io import fastq\n",
        "from nucleus.io import fasta\n",
        "from nucleus.io import sam\n",
        "from nucleus.io import vcf\n",
        "from nucleus.io.genomics_writer import TFRecordWriter\n",
        "from nucleus.protos import reads_pb2\n",
        "from nucleus.util import cigar\n",
        "from nucleus.util import ranges\n",
        "from nucleus.util import utils\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#matplotlib per il plot dell'accuratezza del modello in base ad ogni epoca\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#librerie per la creazione del vocabolario\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#librerie per la costruzione della rete neurale RNN\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98V_jRj4PROA"
      },
      "source": [
        "#Generazione di dataset randomici"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDVaV9F9PVRs"
      },
      "source": [
        "bases_list = [\"A\",\"C\",\"G\",\"T\"]\n",
        "seq_length = 20 #lunghezza stringa\n",
        "seq_num = 20 #lunghezza dataset\n",
        "\n",
        "dna_not_sanitized = []\n",
        "dna_sanitized = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETl6UmH-CDh"
      },
      "source": [
        "def random_seq_generation(n_seq, seq_len, dataset):\n",
        "  for index in range(n_seq):\n",
        "    sequence = [random.choice(bases_list) for _ in range(seq_len)]\n",
        "    sequence = \"\".join(sequence)\n",
        "    dataset.append(sequence)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwW6If7-lQL"
      },
      "source": [
        "random_seq_generation(seq_num, seq_length, dna_not_sanitized)\n",
        "random_seq_generation(seq_num, seq_length, dna_sanitized)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJvyYzMpeZZ"
      },
      "source": [
        "#Caricamento e analisi di dati reali (in questo caso trascurare la precedente sezione di generazione di dataset randomici)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGydAYSlqKNs"
      },
      "source": [
        "Collegamento al drive e import dei dati reali"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhdq0_cqA6n"
      },
      "source": [
        "#accesso al drive\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_GFYpDekiyK"
      },
      "source": [
        "path_not_sanitized = \"/content/drive/MyDrive/fastQ_data/fastQ_01_2021/ERX149279.fastq.gz\"\n",
        "path_sanitized = \"/content/drive/MyDrive/fastQ_data/fastQ_01_2021/ERX149293.fastq.gz\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oKteMsGkDjq"
      },
      "source": [
        "def seq_isolation(dataset, dataset_len, seq_dataset):\n",
        "  index = 0\n",
        "  seq_list = []\n",
        "\n",
        "  for i in dataset:\n",
        "    if index < dataset_len:\n",
        "      seq_list.append(i)\n",
        "      b = str(list(seq_list)[index]).split(\"\\n\")[2]\n",
        "      seq = \"\"\n",
        "      for j in b:\n",
        "        if j == \"A\" or j == \"C\" or j == \"G\" or j == \"T\":\n",
        "          seq += j\n",
        "      seq_dataset.append(seq)\n",
        "      index += 1\n",
        "    else:\n",
        "      break;"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TOPJEY8kIDk"
      },
      "source": [
        "dataset_length = 50 #se non si usa questo flag l'iterazione sul fastq restituisce: \"Failed to parse FASTQ record\"  "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjKPXZltkQ-s"
      },
      "source": [
        "Creazione della lista contenente solo le sequenze dei due fastq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXc_iQTgkMDc"
      },
      "source": [
        "#lista dna non sanificato -> dna_not_sanitized\n",
        "fastq_dataset_not_sanitized = fastq.FastqReader(path_not_sanitized)\n",
        "\n",
        "dna_not_sanitized = []\n",
        "seq_isolation(fastq_dataset_not_sanitized, dataset_length, dna_not_sanitized)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vayNv_C3k9nl"
      },
      "source": [
        "#lista dna sanificato -> dna_sanitized\n",
        "fastq_dataset_sanitized = fastq.FastqReader(path_sanitized)\n",
        "\n",
        "dna_sanitized = []\n",
        "seq_isolation(fastq_dataset_sanitized, dataset_length, dna_sanitized)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1lKWqV6qaRT"
      },
      "source": [
        "Visualizzazione del fastQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt9FrIPEsXsf"
      },
      "source": [
        "Check sulla lunghezza delle sequenze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKNr1LGxsZ4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0199caed-3924-4011-ceae-510151c1f0ad"
      },
      "source": [
        "#Lunghezza massima e minima del dataset \"not_sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_not_sanitized: \" , len(max(dna_not_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_not_sanitized: \" , len(min(dna_not_sanitized, key=len)), \"\\n\")\n",
        "\n",
        "#Lunghezza massima e minima del dataset \"sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_sanitized: \" ,  len(max(dna_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_sanitized: \" , len(min(dna_sanitized, key=len)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunghezza massima delle sequenze dna_not_sanitized:  76\n",
            "Lunghezza minima delle sequenze dna_not_sanitized:  76 \n",
            "\n",
            "Lunghezza massima delle sequenze dna_sanitized:  76\n",
            "Lunghezza minima delle sequenze dna_sanitized:  76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nm26iWyti0e"
      },
      "source": [
        "Check che verifica se la sequenza ha qualche parametro \"K\", il quale indica un'imprecisione in fase di campionamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jSNcbOtr8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b2dfd2-0294-4552-c74b-971ca50591c7"
      },
      "source": [
        "def sequences_check(sequences_list):\n",
        "  i = 0\n",
        "\n",
        "  for single_sequence in sequences_list:\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        return True\n",
        "    i+= 1\n",
        "  return False\n",
        "  \n",
        "print(\"Check delle sequenze non sanificate: \\n\", sequences_check(dna_not_sanitized))\n",
        "print(\"Check delle sequenze  sanificate: \\n\", sequences_check(dna_sanitized))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check delle sequenze non sanificate: \n",
            " False\n",
            "Check delle sequenze  sanificate: \n",
            " False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fee-J8Hv6Xl"
      },
      "source": [
        "Se la funzione \"sequence_check()\" restituisce \"True\" per una delle due liste, procedere con la correzione; altrimenti procedere con la creazione del vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA9OYhpBwKxS"
      },
      "source": [
        "#con questo metodo sostituisco il parametro \"k\" con una delle basi azotate(in questo caso ho scelto l'Adenina)\n",
        "def sequences_correction(sequences_list): \n",
        "  j = 0\n",
        "  new_dna_sequence_list = []\n",
        "  for single_sequence in sequences_list:\n",
        "    i = 0\n",
        "    new_sequence = \"\"\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        new_sequence+=\"A\"\n",
        "      else:\n",
        "        new_sequence+=index\n",
        "      i+=1\n",
        "    new_dna_sequence_list.append(new_sequence)  \n",
        "    j+=1     \n",
        "\n",
        "  sequences_list = new_dna_sequence_list\n",
        "  return sequences_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXACHaqy05hm"
      },
      "source": [
        "sequences_correction(dna_not_sanitized)\n",
        "sequences_correction(dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJqAwxPCSsio"
      },
      "source": [
        "#Creo il vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqTGuXyUac1t",
        "outputId": "feb98d52-d441-4c2a-98a0-6837c4af40eb"
      },
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "\n",
        "tokenizer.fit_on_texts(dna_not_sanitized)\n",
        "\n",
        "vocab = tokenizer.word_index\n",
        "vocab_length = len(vocab) + 1\n",
        "\n",
        "print(\"Vocabulary: \" ,vocab)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary:  {'c': 1, 'g': 2, 'a': 3, 't': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5uXy2ogTC5s"
      },
      "source": [
        "input_not_sanitized = []\n",
        "\n",
        "for record in dna_not_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([record])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_not_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_not_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_not_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "#xs, labels_x = input_sequences[:,:-1],input_sequences[:,-1] #il -1 omette l'ultimo carattere\n",
        "xs = input_sequences[:,:-1] #il -1 omette l'ultimo carattere"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXv9sV36kk6E",
        "outputId": "b338b857-0a3f-4a41-8216-f168e86f27b6"
      },
      "source": [
        "print(input_sequences)\n",
        "print(input_sequences[:-1])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 3 1]\n",
            " [0 0 0 ... 3 1 1]\n",
            " [0 0 0 ... 1 1 2]\n",
            " ...\n",
            " [0 0 4 ... 2 2 3]\n",
            " [0 4 4 ... 2 3 1]\n",
            " [4 4 2 ... 3 1 1]]\n",
            "[[0 0 0 ... 0 3 1]\n",
            " [0 0 0 ... 3 1 1]\n",
            " [0 0 0 ... 1 1 2]\n",
            " ...\n",
            " [0 0 0 ... 3 2 2]\n",
            " [0 0 4 ... 2 2 3]\n",
            " [0 4 4 ... 2 3 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWSt4TxlUYDG"
      },
      "source": [
        "input_sanitized = []\n",
        "\n",
        "for line in dna_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "ys, labels_y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels_y, num_classes=vocab_length)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnTRmRr_Usus"
      },
      "source": [
        "#Costruzione del modello Rnn con layer LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdnF-T7GW3A"
      },
      "source": [
        "##Modello RNN Bidirezionale(LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnKFEBGnK7MP"
      },
      "source": [
        "**N.B:** Bidirectional fa una copia del layer RNN passatogli come argomento e, attraverso il campo go_backwards, riesce a capovolgere l'input, quindi ad elaborarlo anche in ordine inverso.\n",
        "Questo apporccio non tiene conto solo delle parole successive da generare, ma anche del contesto che c'è intorno al carattere/parola successiva al fine di ottere una migliore predizione, preservando più informazioni utili nel tempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPaav9HU1U-"
      },
      "source": [
        "model = Sequential(name=\"metagenomic prediction\")\n",
        "model.add(Embedding(vocab_length, 110, input_length=max_sequence_len-1, name=\"input_layer\"))\n",
        "model.add(Bidirectional(LSTM(150), name=\"LSTM\"))\n",
        "model.add(Dense(vocab_length, activation='softmax', name=\"last_layer\"))\n",
        "\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dop7BAANU21P",
        "outputId": "05d6a3f7-2921-432c-e89d-0b83f44850b9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"metagenomic prediction\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Embedding)      (None, 19, 110)           550       \n",
            "_________________________________________________________________\n",
            "LSTM (Bidirectional)         (None, 300)               313200    \n",
            "_________________________________________________________________\n",
            "last_layer (Dense)           (None, 5)                 1505      \n",
            "=================================================================\n",
            "Total params: 315,255\n",
            "Trainable params: 315,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsYlsw4_Gbcc"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpqqVH6U4mG",
        "outputId": "8e449b12-1413-4668-aa86-1904f46cad1a"
      },
      "source": [
        "history = model.fit(xs, ys, epochs=40, verbose=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "380/380 [==============================] - 2s 4ms/sample - loss: 1.5137 - accuracy: 0.2553\n",
            "Epoch 2/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.4320 - accuracy: 0.2395\n",
            "Epoch 3/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.4016 - accuracy: 0.2474\n",
            "Epoch 4/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3913 - accuracy: 0.2711\n",
            "Epoch 5/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3829 - accuracy: 0.2895\n",
            "Epoch 6/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3673 - accuracy: 0.3289\n",
            "Epoch 7/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3566 - accuracy: 0.3158\n",
            "Epoch 8/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3649 - accuracy: 0.3026\n",
            "Epoch 9/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3302 - accuracy: 0.3711\n",
            "Epoch 10/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.2966 - accuracy: 0.4000\n",
            "Epoch 11/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.2093 - accuracy: 0.5026\n",
            "Epoch 12/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.1039 - accuracy: 0.5132\n",
            "Epoch 13/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.9953 - accuracy: 0.5658\n",
            "Epoch 14/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.8692 - accuracy: 0.6474\n",
            "Epoch 15/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.7159 - accuracy: 0.7289\n",
            "Epoch 16/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.5159 - accuracy: 0.8316\n",
            "Epoch 17/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.3054 - accuracy: 0.8974\n",
            "Epoch 18/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.2282 - accuracy: 0.9263\n",
            "Epoch 19/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1574 - accuracy: 0.9447\n",
            "Epoch 20/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1376 - accuracy: 0.9447\n",
            "Epoch 21/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1230 - accuracy: 0.9447\n",
            "Epoch 22/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1123 - accuracy: 0.9553\n",
            "Epoch 23/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1147 - accuracy: 0.9368\n",
            "Epoch 24/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1086 - accuracy: 0.9526\n",
            "Epoch 25/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1063 - accuracy: 0.9526\n",
            "Epoch 26/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1054 - accuracy: 0.9368\n",
            "Epoch 27/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1055 - accuracy: 0.9447\n",
            "Epoch 28/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1034 - accuracy: 0.9421\n",
            "Epoch 29/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1009 - accuracy: 0.9474\n",
            "Epoch 30/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0974 - accuracy: 0.9526\n",
            "Epoch 31/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0988 - accuracy: 0.9447\n",
            "Epoch 32/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1001 - accuracy: 0.9474\n",
            "Epoch 33/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1007 - accuracy: 0.9526\n",
            "Epoch 34/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1037 - accuracy: 0.9447\n",
            "Epoch 35/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0937 - accuracy: 0.9447\n",
            "Epoch 36/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0948 - accuracy: 0.9474\n",
            "Epoch 37/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0947 - accuracy: 0.9500\n",
            "Epoch 38/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0904 - accuracy: 0.9605\n",
            "Epoch 39/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0952 - accuracy: 0.9526\n",
            "Epoch 40/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0927 - accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZidmnc-U79N"
      },
      "source": [
        "def plot_graphs(history, string, name_model):\n",
        "  title = \"Visualizzazione della curva di Training del modello \" + name_model\n",
        "  plt.suptitle(title)\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epoche\")\n",
        "  plt.ylabel(ylabel=\"Accuratezza\")\n",
        "  plt.show()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "tt-T68mJU98S",
        "outputId": "7601e195-47af-41f8-b321-4f24c6fe36c3"
      },
      "source": [
        "plot_graphs(history, 'accuracy', \"bidirezionale\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfiDYGL-gxHo"
      },
      "source": [
        "def make_prediction(next_word_len, tokenizer, model, text_to_predict, j):\n",
        "\tfor _ in range(next_word_len):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([text_to_predict])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\ttext_to_predict += \"\" + output_word \n",
        "\t\tj += \"\" + output_word \n",
        "\t\tnew_sequence = \"\".join(j) #isolo la nuova sequenza generata\n",
        "\treturn new_sequence"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143wOQzGFQlL"
      },
      "source": [
        "## Predizione partendo da metà sequenza non sanificata appartenente al dataset di partenza utilizzato per il training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RvJrUsGH3nL",
        "outputId": "11c6438a-61ea-4810-dab5-d3be79f56df0"
      },
      "source": [
        "#predizione con metà sequenza esistente\n",
        "existing_dna_seq = dna_not_sanitized[1]\n",
        "half_seq_length = int(seq_length / 2)\n",
        "\n",
        "\n",
        "text_to_predict = existing_dna_seq[0:10]\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "print(new_sequence) #concatenazione tra sequenza passata in input e la nuova generata"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tatacggagt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95KCZvvAHxdo",
        "outputId": "5e1ed999-a34d-4b2a-db8c-1c3c296a2e7d"
      },
      "source": [
        "print(\"Dna not sanitized in pos 0:\" , dna_not_sanitized[1])\n",
        "print(\"Dna sanitized in pos 0:    \" ,dna_sanitized[1])\n",
        "print(vocab)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dna not sanitized in pos 0: ACGTCAGGTAGTTCAACTAT\n",
            "Dna sanitized in pos 0:     CGATGCATTCTTAACGGAGT\n",
            "{'c': 1, 'g': 2, 'a': 3, 't': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybE9QpyqGCHM"
      },
      "source": [
        "##Predizione partendo da metà sequenza randomica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ONs5spxg1rp",
        "outputId": "6cf39f75-3e6d-41f7-9ccc-83d1ab707ffa"
      },
      "source": [
        "#genero metà sequenza di dna non sanificato\n",
        "half_seq_length = int(seq_length / 2)\n",
        "half_sequence = [random.choice(bases_list) for _ in range(half_seq_length)]\n",
        "half_sequence = \"\".join(half_sequence)\n",
        "\n",
        "print(half_sequence)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ATCGAGAAAG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZx5OkTB-5_R",
        "outputId": "7adb1307-9a6d-4c4e-b658-4ee1f6e96903"
      },
      "source": [
        "text_to_predict = half_sequence\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "#new_sequence , text_to_predict = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "#print(text_to_predict) #concatenazione tra sequenza passata in input e la nuova generata\n",
        "print(new_sequence)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acggaagacc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ienvjiiw8_"
      },
      "source": [
        "def make_upper(text, index):\n",
        "  s = \"\"\n",
        "  for i in text:\n",
        "    if i == \"a\":\n",
        "      s = \"A\"\n",
        "    if i == \"c\":\n",
        "      s = \"C\"\n",
        "    if i == \"g\":\n",
        "      s = \"G\"\n",
        "    if i == \"t\":\n",
        "      s = \"T\"\n",
        "    index += \"\" + s\n",
        "    text = \"\".join(index)\n",
        "  return text"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmnP9ZmvsYTq",
        "outputId": "8256116d-87f8-4173-c792-4766e510f317"
      },
      "source": [
        "increase_sequence = \"\"\n",
        "print(make_upper(new_sequence, increase_sequence))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACGGAAGACC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievTU1NIGin9"
      },
      "source": [
        "##Predizione di una sequenza costituita da 440 caratteri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbyPwmy2ac9"
      },
      "source": [
        " Come si procede? Si scompone la sequenza lunga 440 in 44 sottosequenze, ognuna lunga 10 caratteri (questo perchè il modello risulta accurato per la predizione di stringhe lunghe 10 caratteri); poi per ognuna si genera la sequenza sanificata; infine si costruisce la sequenza finale tenendo conto dell'ordine di partenza relativo alle sottosequenze.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scHVDYYgaVdv"
      },
      "source": [
        "rnd_max_len = 440\n",
        "sub_seq_len = 10\n",
        "n_sub_seq = 44\n",
        "not_sanitized_max = []\n",
        "sub_seq_data = []\n",
        "\n",
        "random_seq_generation(1, rnd_max_len, not_sanitized_max)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zECPPK0d-vLo"
      },
      "source": [
        "sequence = not_sanitized_max[0]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqFPcbb_BOG"
      },
      "source": [
        "#grazie a questa funzione si riesce a dividere l'intera sequenza di lunghezza 440 in 44 sottosequenze, ognuna di 10 caratteri; si crea, quindi, una lista di sottosequenza\n",
        "def sub_seq_data_generator(entire_sequence, sub_len, n_sub_seq):\n",
        "  for i in range(n_sub_seq):\n",
        "    sub_seq = entire_sequence[i*sub_len:(i+1)*sub_len]\n",
        "    sub_seq_data.append(sub_seq)\n",
        "\n",
        "  return sub_seq_data"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_b6VhjCFHd"
      },
      "source": [
        "sub_seq_data = sub_seq_data_generator(sequence, sub_seq_len, n_sub_seq)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5g6QXOHkWx"
      },
      "source": [
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "sanitized_sub_seq_data = []\n",
        "increase_sequence = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_sub_seq_data.append(make_prediction(next_words, tokenizer, model, sub_seq_data[i], increase_sequence))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgITChfEO9Jm"
      },
      "source": [
        "sanitized_max = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_max += sanitized_sub_seq_data[i]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqaslNI_1ww7",
        "outputId": "40909f25-a354-4bbd-c804-aa2e692be71b"
      },
      "source": [
        "print(\"Sequenza sanificata    : \" , make_upper(sanitized_max, \"\"))\n",
        "print(\"Sequenza non sanificata: \" , sequence)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequenza sanificata    :  TGCGGGGGGGAACAACTCACCCGGTAGTATACCTCGCGGGTGGGGGGGGGCCCCCGCGCGTCTCTAGTGACGGTCGGGGGGCCGCGGGGGCGACGATATTACGCTGGGGGCGCGCGCCTCAGGGGGGGGGGTCTATCGGTGGGGGGGGGGTAGGGGGGGGCGGGGGGGGGTCTGTTTTGGTCTCGTGTCCGGGGGGGGGGTATATATATTGGCGCGCGGGCGCGGGGGGGGTGAGGGGGGAGAGAGGGGGGGGGGGGGGGGTTTCCCGTTATACCGGTTCATTCCGTGTGGGGGGGGGGGTCGGCGGCGCTCTATATTGTTGCGGTCTGACTATTGTTCGGCCCGCGCGCTCTGCTCTCGGCTATGCCACTATATTAGTCAGTAGGGAGTACTCTCTCCAGACAGGCGGTACGTATGTAGTGAAGACATGTTTCGCCGC\n",
            "Sequenza non sanificata:  CTCAAGCCGGTGAGGGGAAGACATCGATTCTGCATTGGATTGTTGACCGGGTCTCGGAGAGTACCAGGCGGCAATTATTCCGCCAGTCTCGAAACCTCCCGGATGTGGACTCCGTTTTGGGTAACGAAGGTGAACTAAGACTAAACTTGAACGTAGGTTGCTGAAACCTTCTTCCAAATAATCTTCGAAGCTCAGTCGTCGAGGGGGGCTTTTAAACGCCGATGGGTGTCGTAAACATAATCCCATTTGTTTTAGTTGGCGCTGGTCCATAACTGCGAGAGAGCAGTAATATCTGGGGCTTCGTTCACTGCGCAGTGCAGTTATCAAGCCCCTTCCAAGTCATTCGTTGTCGCCTACCAATACCCTCCCCAACCTTTTAGATGTGAGGGTCCTGGAGGCAGCGAAACGGAGGAAGTTTGTCCAGACTTACTTACCCCTTC\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}