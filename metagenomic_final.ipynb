{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metagenomic_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RRdnF-T7GW3A",
        "SsYlsw4_Gbcc",
        "143wOQzGFQlL"
      ],
      "authorship_tag": "ABX9TyM4LGgzo0CYkqn73t4Xrwfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xelanac/metagenomic_project/blob/main/metagenomic_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AruxVWPFnO"
      },
      "source": [
        "#Import delle librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDP2iYK4O-X6"
      },
      "source": [
        "%%capture\n",
        "!pip3 install google-nucleus==0.4.0\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#librerie per la lettura dei file fastq\n",
        "from nucleus.io import fastq\n",
        "from nucleus.io import fasta\n",
        "from nucleus.io import sam\n",
        "from nucleus.io import vcf\n",
        "from nucleus.io.genomics_writer import TFRecordWriter\n",
        "from nucleus.protos import reads_pb2\n",
        "from nucleus.util import cigar\n",
        "from nucleus.util import ranges\n",
        "from nucleus.util import utils\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#matplotlib per il plot dell'accuratezza del modello in base ad ogni epoca\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#librerie per la creazione del vocabolario\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#librerie per la costruzione della rete neurale RNN\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98V_jRj4PROA"
      },
      "source": [
        "#Generazione di dataset randomici"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDVaV9F9PVRs"
      },
      "source": [
        "bases_list = [\"A\",\"C\",\"G\",\"T\"]\n",
        "seq_length = 20\n",
        "seq_num = 20\n",
        "\n",
        "dna_not_sanitized = []\n",
        "dna_sanitized = []"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETl6UmH-CDh"
      },
      "source": [
        "def random_seq_generation(n_seq, seq_len, dataset):\n",
        "  for index in range(n_seq):\n",
        "    sequence = [random.choice(bases_list) for _ in range(seq_len)]\n",
        "    sequence = \"\".join(sequence)\n",
        "    dataset.append(sequence)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwW6If7-lQL"
      },
      "source": [
        "random_seq_generation(seq_num, seq_length, dna_not_sanitized)\n",
        "random_seq_generation(seq_num, seq_length, dna_sanitized)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJvyYzMpeZZ"
      },
      "source": [
        "#Caricamento e analisi di dati reali (in questo caso trascurare la precedente sezione di generazione di dataset randomici)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGydAYSlqKNs"
      },
      "source": [
        "Collegamento al drive e import dei dati reali"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhdq0_cqA6n"
      },
      "source": [
        "#l'accesso al drive non è stato fatto attrsverso il codice, ma cliccando sull'icona della cartella drive\n",
        "#riporto, sottoforma di commento, anche il codice per montarlo\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\" \n",
        "# Leggo il file grezzo fastq con la libreria\n",
        "input_path_not_sanitized = \"/content/drive/My Drive/fastQ_data/T0-R2-U1.R1.fastq\"\n",
        "input_path_sanitized = \"/content/drive/My Drive/fastQ_data/T0-R2-U3.R1.fastq\"\n",
        "\n",
        "fastq_data_not_sanitized = fastq.FastqReader(input_path_not_sanitized)\n",
        "fastq_data_sanitized = fastq.FastqReader(input_path_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1lKWqV6qaRT"
      },
      "source": [
        "Visualizzazione del fastQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHUIOCoxqUpy"
      },
      "source": [
        "def read_fastq_structure(dataset):\n",
        "  for i in dataset:\n",
        "    print(i)\n",
        "    break;\n",
        "\n",
        "print(\"Dataset campionato prima dell'azione danificante: \" , read_fastq_structure(dna_not_sanitized , \"\\n\"))\n",
        "print(\"Dataset campionato dopo l'azione danificante: \", read_fastq_structure(dna_sanitized, \"\\n\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOIOfifdrOl5"
      },
      "source": [
        "Funzione per l'isolamento delle sequenze\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgKzZ5nrQ-i"
      },
      "source": [
        "# Definisco un metodo per la lettura di un record della libreria FASTQ\n",
        "# Eventualmente rivediamo il metodo ora lo prendo per buono ma c'è qualcosa che non va\n",
        "# Se lo lanci due volte sfalsa l'output\n",
        "\n",
        "def seq_isolation(fastq_data, seq_list, single_record):\n",
        "    seq_list.append(single_record)\n",
        "    single_sequence = str(seq_list[0])\n",
        "    single_record_list = single_sequence.split(\"\\n\") #lista contenente le proprietà di una singola sequenza(id, sequence, quality)\n",
        "\n",
        "    fastq_sequence = single_record_list[2].split(\" \") #2 è la posizione della sequenza\n",
        "    final_sequence = fastq_sequence[1] #posizione nella nuova lista\n",
        "    new_sequence = \"\"\n",
        "\n",
        "    for i in final_sequence: #tolgo le \"\" dalla stringa\n",
        "      if i != '\"':\n",
        "        new_sequence += i\n",
        "\n",
        "    final_sequence = new_sequence\n",
        "    #print(final_sequence)\n",
        "    return final_sequence  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkpu9Fl0rbqM"
      },
      "source": [
        "**Inizio dell'analisi dei dati**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz7_pO84rdkW"
      },
      "source": [
        "# Creo due liste contenenti rispettivamente le sequenze del dna campionate prima e dopo l'azione sanificante\n",
        "fastq_data_list = []\n",
        "dna_not_sanitized = []\n",
        "dna_sanitized = []\n",
        "\n",
        "for index in fastq_data_not_sanitized:\n",
        "  dna_not_sanitized.append(seq_isolation(fastq_data_not_sanitized, fastq_data_list, index))\n",
        "\n",
        "fastq_data_list = []\n",
        "\n",
        "for index in fastq_data_sanitized:\n",
        "  dna_not_sanitized.append(seq_isolation(fastq_data_not_sanitized, fastq_data_list, index))\n",
        "\n",
        "# Stampo il numero di sequenze del dataset \"not_sanitized\"\n",
        "len(dna_not_sanitized)\n",
        "# Stampo il numero di sequenze del dataset \"sanitized\"\n",
        "len(dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt9FrIPEsXsf"
      },
      "source": [
        "Check sulla lunghezza delle sequenze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKNr1LGxsZ4Z"
      },
      "source": [
        "#Lunghezza massima e minima del dataset \"not_sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_not_sanitized: \" , len(max(dna_not_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_not_sanitized: \" , len(min(dna_not_sanitized, key=len)), \"\\n\")\n",
        "\n",
        "#Lunghezza massima e minima del dataset \"sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_sanitized: \" ,  len(max(dna_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_sanitized: \" , len(min(dna_sanitized, key=len)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nm26iWyti0e"
      },
      "source": [
        "Check che verifica se la sequenza ha qualche parametro \"K\", il quale indica un'imprecisione in fase di campionamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jSNcbOtr8H"
      },
      "source": [
        "def sequences_check(sequences_list):\n",
        "  i = 0\n",
        "\n",
        "  for single_sequence in sequences_list:\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        return True\n",
        "    i+= 1\n",
        "  return False\n",
        "  \n",
        "print(\"Check delle sequenze non sanificate: \\n\", sequence_check(dna_not_sanitized))\n",
        "print(\"Check delle sequenze  sanificate: \\n\", sequence_check(dna_sanitized))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fee-J8Hv6Xl"
      },
      "source": [
        "Se la funzione \"sequence_check\" restituisce \"True per una delle due liste, procedere con la correzione; altrimenti procedere con la creazione del vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA9OYhpBwKxS"
      },
      "source": [
        "#con questo metodo sostituisco il parametro \"k\" con una delle basi azotate(in questo caso ho scelto l'Adenina)\n",
        "def sequences_correction(sequences_list): \n",
        "  j = 0\n",
        "  new_dna_sequence_list = []\n",
        "  for single_sequence in sequences_list:\n",
        "    i = 0\n",
        "    new_sequence = \"\"\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        new_sequence+=\"A\"\n",
        "      else:\n",
        "        new_sequence+=index\n",
        "      i+=1\n",
        "    new_dna_sequence_list.append(new_sequence)  \n",
        "    j+=1     \n",
        "\n",
        "  sequences_list = new_dna_sequence_list\n",
        "  return sequences_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXACHaqy05hm"
      },
      "source": [
        "sequences_correction(dna_not_sanitized)\n",
        "sequences_correctio(dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJqAwxPCSsio"
      },
      "source": [
        "#Creo il vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqTGuXyUac1t",
        "outputId": "38492cd2-bed5-4f0a-a661-f1e2d06f57d6"
      },
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "\n",
        "tokenizer.fit_on_texts(dna_not_sanitized)\n",
        "\n",
        "vocab = tokenizer.word_index\n",
        "vocab_length = len(vocab) + 1\n",
        "\n",
        "print(\"Vocabulary: \" ,vocab)\n",
        "#type(vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary:  {'g': 1, 't': 2, 'a': 3, 'c': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5uXy2ogTC5s"
      },
      "source": [
        "input_not_sanitized = []\n",
        "\n",
        "for line in dna_not_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_not_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_not_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_not_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "#xs, labels_x = input_sequences[:,:-1],input_sequences[:,-1] #il -1 omette l'ultimo carattere\n",
        "xs = input_sequences[:,:-1] #il -1 omette l'ultimo carattere\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXv9sV36kk6E",
        "outputId": "6e34dfce-42a0-44c6-8299-eec9a4d50d85"
      },
      "source": [
        "print(input_sequences)\n",
        "print(input_sequences[:-1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 4 2]\n",
            " [0 0 0 ... 4 2 1]\n",
            " [0 0 0 ... 2 1 4]\n",
            " ...\n",
            " [0 0 4 ... 2 2 3]\n",
            " [0 4 1 ... 2 3 4]\n",
            " [4 1 2 ... 3 4 2]]\n",
            "[[0 0 0 ... 0 4 2]\n",
            " [0 0 0 ... 4 2 1]\n",
            " [0 0 0 ... 2 1 4]\n",
            " ...\n",
            " [0 0 0 ... 3 2 2]\n",
            " [0 0 4 ... 2 2 3]\n",
            " [0 4 1 ... 2 3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWSt4TxlUYDG"
      },
      "source": [
        "input_sanitized = []\n",
        "\n",
        "for line in dna_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "ys, labels_y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels_y, num_classes=vocab_length)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnTRmRr_Usus"
      },
      "source": [
        "#Costruzione del modello Rnn con layer LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdnF-T7GW3A"
      },
      "source": [
        "##Modello RNN Bidirezionale(LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPaav9HU1U-"
      },
      "source": [
        "model = Sequential(name=\"metagenomic prediction\")\n",
        "model.add(Embedding(vocab_length, 110, input_length=max_sequence_len-1, name=\"input_layer\"))\n",
        "model.add(Bidirectional(LSTM(150), name=\"LSTM\"))\n",
        "model.add(Dense(vocab_length, activation='softmax', name=\"last_layer\"))\n",
        "\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dop7BAANU21P",
        "outputId": "3acd3035-6e48-44bc-9895-c4f58deb27e9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"metagenomic prediction\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Embedding)      (None, 19, 110)           550       \n",
            "_________________________________________________________________\n",
            "LSTM (Bidirectional)         (None, 300)               313200    \n",
            "_________________________________________________________________\n",
            "last_layer (Dense)           (None, 5)                 1505      \n",
            "=================================================================\n",
            "Total params: 315,255\n",
            "Trainable params: 315,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsYlsw4_Gbcc"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpqqVH6U4mG",
        "outputId": "07bfa00d-d494-4ac2-8f38-9b4cf4251946"
      },
      "source": [
        "history = model.fit(xs, ys, epochs=40, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "380/380 [==============================] - 1s 4ms/sample - loss: 1.5543 - accuracy: 0.2342\n",
            "Epoch 2/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.4386 - accuracy: 0.2447\n",
            "Epoch 3/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3954 - accuracy: 0.2895\n",
            "Epoch 4/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3814 - accuracy: 0.2921\n",
            "Epoch 5/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3744 - accuracy: 0.3132\n",
            "Epoch 6/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3607 - accuracy: 0.3289\n",
            "Epoch 7/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3433 - accuracy: 0.3500\n",
            "Epoch 8/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3505 - accuracy: 0.3553\n",
            "Epoch 9/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3117 - accuracy: 0.3816\n",
            "Epoch 10/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.3103 - accuracy: 0.3737\n",
            "Epoch 11/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.2391 - accuracy: 0.4132\n",
            "Epoch 12/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.2800 - accuracy: 0.4342\n",
            "Epoch 13/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.1214 - accuracy: 0.5026\n",
            "Epoch 14/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.9494 - accuracy: 0.6263\n",
            "Epoch 15/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.8473 - accuracy: 0.6684\n",
            "Epoch 16/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.6242 - accuracy: 0.7842\n",
            "Epoch 17/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.4696 - accuracy: 0.8447\n",
            "Epoch 18/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.3533 - accuracy: 0.8921\n",
            "Epoch 19/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.2390 - accuracy: 0.9316\n",
            "Epoch 20/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1733 - accuracy: 0.9368\n",
            "Epoch 21/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1401 - accuracy: 0.9447\n",
            "Epoch 22/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1208 - accuracy: 0.9395\n",
            "Epoch 23/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1211 - accuracy: 0.9421\n",
            "Epoch 24/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1136 - accuracy: 0.9447\n",
            "Epoch 25/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1129 - accuracy: 0.9395\n",
            "Epoch 26/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1106 - accuracy: 0.9474\n",
            "Epoch 27/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1021 - accuracy: 0.9553\n",
            "Epoch 28/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1071 - accuracy: 0.9421\n",
            "Epoch 29/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1061 - accuracy: 0.9474\n",
            "Epoch 30/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1003 - accuracy: 0.9500\n",
            "Epoch 31/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1086 - accuracy: 0.9395\n",
            "Epoch 32/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1003 - accuracy: 0.9447\n",
            "Epoch 33/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0988 - accuracy: 0.9500\n",
            "Epoch 34/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1009 - accuracy: 0.9526\n",
            "Epoch 35/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1033 - accuracy: 0.9421\n",
            "Epoch 36/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1008 - accuracy: 0.9526\n",
            "Epoch 37/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0955 - accuracy: 0.9474\n",
            "Epoch 38/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0994 - accuracy: 0.9421\n",
            "Epoch 39/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1070 - accuracy: 0.9474\n",
            "Epoch 40/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0966 - accuracy: 0.9526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZidmnc-U79N"
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(ylabel=\"Accuratezza\")\n",
        "  plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tt-T68mJU98S",
        "outputId": "28cc94ed-db0d-45dd-e108-5e89b6260f5c"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ONs5spxg1rp",
        "outputId": "35b300f0-1d3f-4422-c243-c35ec47507a3"
      },
      "source": [
        "#genero metà sequenza di dna non sanificato\n",
        "half_seq_length = int(seq_length / 2)\n",
        "half_sequence = [random.choice(bases_list) for _ in range(half_seq_length)]\n",
        "half_sequence = \"\".join(half_sequence)\n",
        "\n",
        "print(half_sequence)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TCTGTAATGG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfiDYGL-gxHo"
      },
      "source": [
        "def make_prediction(next_word_len, tokenizer, model, text_to_predict, j):\n",
        "\tfor _ in range(next_word_len):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([text_to_predict])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\ttext_to_predict += \"\" + output_word \n",
        "\t\tj += \"\" + output_word \n",
        "\t\tnew_sequence = \"\".join(j) #isolo la nuova sequenza generata\n",
        "\treturn new_sequence"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143wOQzGFQlL"
      },
      "source": [
        "## Predizione partendo da metà sequenza non sanificata appartenente al dataset in input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RvJrUsGH3nL",
        "outputId": "3b4e57c7-57e7-4f4a-dae4-bbc005db6956"
      },
      "source": [
        "#predizione con metà sequenza esistente\n",
        "existing_dna_seq = dna_not_sanitized[1]\n",
        "half_seq_length = int(seq_length / 2)\n",
        "\n",
        "\n",
        "text_to_predict = existing_dna_seq[0:10]\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "print(new_sequence) #concatenazione tra sequenza passata in input e la nuova generata"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ccggaccccg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95KCZvvAHxdo",
        "outputId": "2a50ba0c-56b9-4bd4-fe78-19a081804c54"
      },
      "source": [
        "print(\"Dna not sanitized in pos 0:\" , dna_not_sanitized[1])\n",
        "print(\"Dna sanitized in pos 0:    \" ,dna_sanitized[1])\n",
        "print(vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dna not sanitized in pos 0: TTACCGTCAATCAGATATGA\n",
            "Dna sanitized in pos 0:     ACGTAGGGCACCGCACCCCT\n",
            "{'g': 1, 't': 2, 'a': 3, 'c': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybE9QpyqGCHM"
      },
      "source": [
        "##Predizione partendo da metà sequenza randomica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZx5OkTB-5_R",
        "outputId": "15bccd98-6cb4-45a0-b59d-dfe3ce87c955"
      },
      "source": [
        "text_to_predict = half_sequence\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "#new_sequence , text_to_predict = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "#print(text_to_predict) #concatenazione tra sequenza passata in input e la nuova generata\n",
        "print(new_sequence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tgtatatcgg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ienvjiiw8_"
      },
      "source": [
        "def make_upper(text, index):\n",
        "  s = \"\"\n",
        "  for i in text:\n",
        "    if i == \"a\":\n",
        "      s = \"A\"\n",
        "    if i == \"c\":\n",
        "      s = \"C\"\n",
        "    if i == \"g\":\n",
        "      s = \"G\"\n",
        "    if i == \"t\":\n",
        "      s = \"T\"\n",
        "    index += \"\" + s\n",
        "    text = \"\".join(index)\n",
        "  return text"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmnP9ZmvsYTq",
        "outputId": "1d4aa74f-35a9-493b-a205-321f2bb82c33"
      },
      "source": [
        "increase_sequence = \"\"\n",
        "print(make_upper(new_sequence, increase_sequence))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TGTATATCGG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievTU1NIGin9"
      },
      "source": [
        "##Predizione di una sequenza costituita da 440 caratteri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbyPwmy2ac9"
      },
      "source": [
        " Come si procede? Si scompone la sequenza lunga 440 in 44 sottosequenze, ognuna lunga 40 caratteri (questo perchè il modello risulta accurato per la predizione di stringhe lunghe 10 caratteri); poi per ognuna si genera la sequenza sanificata; infine si costruisce la sequenza finale tenendo conto dell'ordine di partenza relativo alle sottosequenze.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scHVDYYgaVdv"
      },
      "source": [
        "rnd_max_len = 440\n",
        "sub_seq_len = 10\n",
        "n_sub_seq = 44\n",
        "not_sanitized_max = []\n",
        "sub_seq_data = []\n",
        "\n",
        "random_seq_generation(1, rnd_max_len, not_sanitized_max)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zECPPK0d-vLo"
      },
      "source": [
        "sequence = not_sanitized_max[0]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqFPcbb_BOG"
      },
      "source": [
        "#grazie a questa funzione si riesce a dividere l'intera sequenza di lunghezza 440 in 44 sottosequenze, ognuna di 10 caratteri; si crea, quindi, una lista di sottosequenza\n",
        "def sub_seq_data_generator(entire_sequence, sub_len, n_sub_seq):\n",
        "  for i in range(n_sub_seq):\n",
        "    sub_seq = entire_sequence[i*sub_len:(i+1)*sub_len]\n",
        "    sub_seq_data.append(sub_seq)\n",
        "\n",
        "  return sub_seq_data"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_b6VhjCFHd"
      },
      "source": [
        "sub_seq_data = sub_seq_data_generator(sequence, sub_seq_len, n_sub_seq)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5g6QXOHkWx"
      },
      "source": [
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "sanitized_sub_seq_data = []\n",
        "increase_sequence = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_sub_seq_data.append(make_prediction(next_words, tokenizer, model, sub_seq_data[i], increase_sequence))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgITChfEO9Jm"
      },
      "source": [
        "sanitized_max = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_max += sanitized_sub_seq_data[i]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqaslNI_1ww7",
        "outputId": "73ec8039-80fe-4e54-ca68-826eeb92d5b8"
      },
      "source": [
        "print(\"Sequenza sanificata    : \" , make_upper(sanitized_max, \"\"))\n",
        "print(\"Sequenza non sanificata: \" , sequence)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequenza sanificata    :  TATAGTCCGGTAGTGTATCCTATGTCTCGGGGTGTCGTGCAGCGACGCATCAGGAGTACCGTGTTCCGTCATCGGACATCGGGGTTACACGTAGTCCGTCGCTCCAAGCGCTTCTCTCAGCGCGGATTCCGGTCCGTGTCCGCAGGCAGCCGTATACAGCCAGCCGACAGACGTGGATTAGAGACACCGGCGTGTACAGGGTGTACATCGGAGTTATCTCGTGTATAGCCCGGAGTAGACGGGTTACATCGTACATTCACTATACGTCCGAGGGACACGCGGGACACACCCGGAGTACATTAGTGTACCGTATATGTCGGTTGTATTCCGTATGTCGGGCAAACCCCTTCGGGAGTTACCGTAGTCCGTCGGAGTACAGCCTCGGTCCCCGTGTCCGTCCTATACAGGCCACGTGTACCCAGCGACGCCTAACGACACCG\n",
            "Sequenza non sanificata:  TGAATGTATGATTGGTACTACGTGCGAAGAAGAAGTCCTACAAGCTCCGCAGTAGATGTATGGTCTTCTTGACTTTGAAACATATTCTTTCACCGTGATTCTCCATGGCTCAACGCTCACTATCAGTAATACTACATTTCAAGTACCAATTGGGCAGTTACCAGAGGTCGGATGAAGTTCCCTACCGAAGGGTTTGTACTGCACGGTACCCTTTTACGGGATTGTTGCCCTGACAACTGCTAGAATTATAGCGGGGGGGAGCTACGAGAGGATTTGCCTAGGGAACCACACCTGAATTCAGTGGAGCTTATTAGGGCAGGTCTGCTATTGTGGGCAGAAGGATACGGCCCAGGTGATCTGATAGCGCATTAGTGTCATCCTGTAGGACATTAGTCCCTCGTGTCCCGTAGATAGGAATAGGTCTTCTACAGCGCGAATTA\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}