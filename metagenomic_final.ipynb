{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metagenomic_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RRdnF-T7GW3A",
        "SsYlsw4_Gbcc",
        "143wOQzGFQlL"
      ],
      "mount_file_id": "1fL0-eDKgqVA4MlRSci89QiN6Bhk3Uyol",
      "authorship_tag": "ABX9TyMhvplhmvFz3aSxWfNCyeJt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xelanac/metagenomic-project/blob/main/metagenomic_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AruxVWPFnO"
      },
      "source": [
        "#Import delle librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDP2iYK4O-X6"
      },
      "source": [
        "%%capture\n",
        "!pip3 install google-nucleus==0.4.0\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#librerie per la lettura dei file fastq\n",
        "from nucleus.io import fastq\n",
        "from nucleus.io import fasta\n",
        "from nucleus.io import sam\n",
        "from nucleus.io import vcf\n",
        "from nucleus.io.genomics_writer import TFRecordWriter\n",
        "from nucleus.protos import reads_pb2\n",
        "from nucleus.util import cigar\n",
        "from nucleus.util import ranges\n",
        "from nucleus.util import utils\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#matplotlib per il plot dell'accuratezza del modello in base ad ogni epoca\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#librerie per la creazione del vocabolario\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#librerie per la costruzione della rete neurale RNN\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98V_jRj4PROA"
      },
      "source": [
        "#Generazione di dataset randomici"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDVaV9F9PVRs"
      },
      "source": [
        "bases_list = [\"A\",\"C\",\"G\",\"T\"]\n",
        "seq_length = 20 #lunghezza stringa\n",
        "seq_num = 30 #lunghezza dataset\n",
        "\n",
        "dna_not_sanitized = []\n",
        "dna_sanitized = []"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETl6UmH-CDh"
      },
      "source": [
        "def random_seq_generation(n_seq, seq_len, dataset):\n",
        "  for index in range(n_seq):\n",
        "    sequence = [random.choice(bases_list) for _ in range(seq_len)]\n",
        "    sequence = \"\".join(sequence)\n",
        "    dataset.append(sequence)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwW6If7-lQL"
      },
      "source": [
        "random_seq_generation(seq_num, seq_length, dna_not_sanitized)\n",
        "random_seq_generation(seq_num, seq_length, dna_sanitized)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJvyYzMpeZZ"
      },
      "source": [
        "#Caricamento e analisi di dati reali (in questo caso trascurare la precedente sezione di generazione di dataset randomici)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGydAYSlqKNs"
      },
      "source": [
        "Collegamento al drive e import dei dati reali"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhdq0_cqA6n"
      },
      "source": [
        "#accesso al drive\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_GFYpDekiyK"
      },
      "source": [
        "path_not_sanitized = \"/content/drive/MyDrive/fastQ_data/fastQ_01_2021/ERX149279.fastq.gz\"\n",
        "path_sanitized = \"/content/drive/MyDrive/fastQ_data/fastQ_01_2021/ERX149293.fastq.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oKteMsGkDjq"
      },
      "source": [
        "def seq_isolation(dataset, dataset_len, seq_dataset):\n",
        "  index = 0\n",
        "  seq_list = []\n",
        "\n",
        "  for i in dataset:\n",
        "    if index < dataset_len:\n",
        "      seq_list.append(i)\n",
        "      b = str(list(seq_list)[index]).split(\"\\n\")[2]\n",
        "      seq = \"\"\n",
        "      for j in b:\n",
        "        if j == \"A\" or j == \"C\" or j == \"G\" or j == \"T\":\n",
        "          seq += j\n",
        "      seq_dataset.append(seq)\n",
        "      index += 1\n",
        "    else:\n",
        "      break;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TOPJEY8kIDk"
      },
      "source": [
        "dataset_length = 50 #se non si usa questo flag l'iterazione sul fastq restituisce: \"Failed to parse FASTQ record\"  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjKPXZltkQ-s"
      },
      "source": [
        "Creazione della lista contenente solo le sequenze dei due fastq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXc_iQTgkMDc"
      },
      "source": [
        "#lista dna non sanificato -> dna_not_sanitized\n",
        "fastq_dataset_not_sanitized = fastq.FastqReader(path_not_sanitized)\n",
        "\n",
        "dna_not_sanitized = []\n",
        "seq_isolation(fastq_dataset_not_sanitized, dataset_length, dna_not_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vayNv_C3k9nl"
      },
      "source": [
        "#lista dna sanificato -> dna_sanitized\n",
        "fastq_dataset_sanitized = fastq.FastqReader(path_sanitized)\n",
        "\n",
        "dna_sanitized = []\n",
        "seq_isolation(fastq_dataset_sanitized, dataset_length, dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt9FrIPEsXsf"
      },
      "source": [
        "Check sulla lunghezza delle sequenze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKNr1LGxsZ4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0199caed-3924-4011-ceae-510151c1f0ad"
      },
      "source": [
        "#Lunghezza massima e minima del dataset \"not_sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_not_sanitized: \" , len(max(dna_not_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_not_sanitized: \" , len(min(dna_not_sanitized, key=len)), \"\\n\")\n",
        "\n",
        "#Lunghezza massima e minima del dataset \"sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_sanitized: \" ,  len(max(dna_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_sanitized: \" , len(min(dna_sanitized, key=len)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunghezza massima delle sequenze dna_not_sanitized:  76\n",
            "Lunghezza minima delle sequenze dna_not_sanitized:  76 \n",
            "\n",
            "Lunghezza massima delle sequenze dna_sanitized:  76\n",
            "Lunghezza minima delle sequenze dna_sanitized:  76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nm26iWyti0e"
      },
      "source": [
        "Check che verifica se la sequenza ha qualche parametro \"K\", il quale indica un'imprecisione in fase di campionamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jSNcbOtr8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b2dfd2-0294-4552-c74b-971ca50591c7"
      },
      "source": [
        "def sequences_check(sequences_list):\n",
        "  i = 0\n",
        "\n",
        "  for single_sequence in sequences_list:\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        return True\n",
        "    i+= 1\n",
        "  return False\n",
        "  \n",
        "print(\"Check delle sequenze non sanificate: \\n\", sequences_check(dna_not_sanitized))\n",
        "print(\"Check delle sequenze  sanificate: \\n\", sequences_check(dna_sanitized))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check delle sequenze non sanificate: \n",
            " False\n",
            "Check delle sequenze  sanificate: \n",
            " False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fee-J8Hv6Xl"
      },
      "source": [
        "Se la funzione \"sequence_check()\" restituisce \"True\" per una delle due liste, procedere con la correzione; altrimenti procedere con la creazione del vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA9OYhpBwKxS"
      },
      "source": [
        "#con questo metodo sostituisco il parametro \"k\" con una delle basi azotate(in questo caso ho scelto l'Adenina)\n",
        "def sequences_correction(sequences_list): \n",
        "  j = 0\n",
        "  new_dna_sequence_list = []\n",
        "  for single_sequence in sequences_list:\n",
        "    i = 0\n",
        "    new_sequence = \"\"\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        new_sequence+=\"A\"\n",
        "      else:\n",
        "        new_sequence+=index\n",
        "      i+=1\n",
        "    new_dna_sequence_list.append(new_sequence)  \n",
        "    j+=1     \n",
        "\n",
        "  sequences_list = new_dna_sequence_list\n",
        "  return sequences_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXACHaqy05hm"
      },
      "source": [
        "sequences_correction(dna_not_sanitized)\n",
        "sequences_correction(dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJqAwxPCSsio"
      },
      "source": [
        "#Creo il vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqTGuXyUac1t",
        "outputId": "54731f66-d1b3-44cb-e6d9-cdbab59c0abf"
      },
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "\n",
        "tokenizer.fit_on_texts(dna_not_sanitized)\n",
        "\n",
        "vocab = tokenizer.word_index\n",
        "vocab_length = len(vocab) + 1\n",
        "\n",
        "print(\"Vocabulary: \" ,vocab)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary:  {'t': 1, 'a': 2, 'g': 3, 'c': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5uXy2ogTC5s"
      },
      "source": [
        "input_not_sanitized = []\n",
        "\n",
        "for record in dna_not_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([record])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_not_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_not_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_not_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "#xs, labels_x = input_sequences[:,:-1],input_sequences[:,-1] #il -1 omette l'ultimo carattere\n",
        "xs = input_sequences[:,:-1] #il -1 omette l'ultimo carattere"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXv9sV36kk6E",
        "outputId": "56d1601b-6461-4460-fc4b-cd58a2f8efcd"
      },
      "source": [
        "print(input_sequences)\n",
        "print(input_sequences[:-1])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 1 3]\n",
            " [0 0 0 ... 1 3 4]\n",
            " [0 0 0 ... 3 4 4]\n",
            " ...\n",
            " [0 0 4 ... 4 2 1]\n",
            " [0 4 2 ... 2 1 1]\n",
            " [4 2 4 ... 1 1 1]]\n",
            "[[0 0 0 ... 0 1 3]\n",
            " [0 0 0 ... 1 3 4]\n",
            " [0 0 0 ... 3 4 4]\n",
            " ...\n",
            " [0 0 0 ... 4 4 2]\n",
            " [0 0 4 ... 4 2 1]\n",
            " [0 4 2 ... 2 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWSt4TxlUYDG"
      },
      "source": [
        "input_sanitized = []\n",
        "\n",
        "for line in dna_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "ys, labels_y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels_y, num_classes=vocab_length)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnTRmRr_Usus"
      },
      "source": [
        "#Costruzione del modello Rnn con layer LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdnF-T7GW3A"
      },
      "source": [
        "##Modello RNN Bidirezionale(LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnKFEBGnK7MP"
      },
      "source": [
        "**N.B:** Bidirectional fa una copia del layer RNN passatogli come argomento e, attraverso il campo go_backwards, riesce a capovolgere l'input, quindi ad elaborarlo anche in ordine inverso.\n",
        "Questo apporccio non tiene conto solo delle parole successive da generare, ma anche del contesto che c'è intorno al carattere/parola successiva al fine di ottere una migliore predizione, preservando più informazioni utili nel tempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPaav9HU1U-"
      },
      "source": [
        "def bidirectional_rnn(vocab, max_seq_len):\n",
        "  print(\"Bidirectional LSTM MODEL\")\n",
        "  model_bidirectional = Sequential(name=\"metagenomic prediction\")\n",
        "  model_bidirectional.add(Embedding(vocab, 110, input_length=max_seq_len, name=\"input_layer\"))\n",
        "  model_bidirectional.add(Bidirectional(LSTM(150), name=\"LSTM\"))\n",
        "  model_bidirectional.add(Dense(vocab, activation='softmax', name=\"last_layer\"))\n",
        "\n",
        "  adam = Adam(lr=0.01)\n",
        "  model_bidirectional.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "  return model_bidirectional"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dop7BAANU21P",
        "outputId": "8d3ba316-1ddb-4489-da7f-7cb4051ee866"
      },
      "source": [
        "model_bidirectional = bidirectional_rnn(vocab_length, max_sequence_len-1)\n",
        "model_bidirectional.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bidirectional LSTM MODEL\n",
            "Model: \"metagenomic prediction\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Embedding)      (None, 19, 110)           550       \n",
            "_________________________________________________________________\n",
            "LSTM (Bidirectional)         (None, 300)               313200    \n",
            "_________________________________________________________________\n",
            "last_layer (Dense)           (None, 5)                 1505      \n",
            "=================================================================\n",
            "Total params: 315,255\n",
            "Trainable params: 315,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsYlsw4_Gbcc"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpqqVH6U4mG",
        "outputId": "8d87bc4a-646b-4116-8f83-c8e4daec9375"
      },
      "source": [
        "history_bidirectional = model_bidirectional.fit(xs, ys, epochs=40, verbose=1)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 2.3055 - accuracy: 0.2561\n",
            "Epoch 2/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.5018 - accuracy: 0.2614\n",
            "Epoch 3/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.4305 - accuracy: 0.2632\n",
            "Epoch 4/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 1.4172 - accuracy: 0.2842\n",
            "Epoch 5/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 1.3696 - accuracy: 0.3193\n",
            "Epoch 6/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 1.3266 - accuracy: 0.3614\n",
            "Epoch 7/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 1.3033 - accuracy: 0.3614\n",
            "Epoch 8/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.2898 - accuracy: 0.3702\n",
            "Epoch 9/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.2699 - accuracy: 0.4053\n",
            "Epoch 10/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.2189 - accuracy: 0.4088\n",
            "Epoch 11/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.1642 - accuracy: 0.4719\n",
            "Epoch 12/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.1485 - accuracy: 0.4614\n",
            "Epoch 13/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 1.0871 - accuracy: 0.5211\n",
            "Epoch 14/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 1.0301 - accuracy: 0.5526\n",
            "Epoch 15/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.9978 - accuracy: 0.5596\n",
            "Epoch 16/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 0.9126 - accuracy: 0.5877\n",
            "Epoch 17/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.8385 - accuracy: 0.6614\n",
            "Epoch 18/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 0.7710 - accuracy: 0.6982\n",
            "Epoch 19/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 0.6999 - accuracy: 0.7246\n",
            "Epoch 20/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.6175 - accuracy: 0.7649\n",
            "Epoch 21/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 0.5532 - accuracy: 0.7772\n",
            "Epoch 22/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 0.4704 - accuracy: 0.8281\n",
            "Epoch 23/40\n",
            "570/570 [==============================] - 1s 3ms/sample - loss: 0.3749 - accuracy: 0.8877\n",
            "Epoch 24/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.3216 - accuracy: 0.8930\n",
            "Epoch 25/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.2566 - accuracy: 0.9070\n",
            "Epoch 26/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.2222 - accuracy: 0.9368\n",
            "Epoch 27/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1915 - accuracy: 0.9351\n",
            "Epoch 28/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1738 - accuracy: 0.9368\n",
            "Epoch 29/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1579 - accuracy: 0.9404\n",
            "Epoch 30/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1401 - accuracy: 0.9439\n",
            "Epoch 31/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1339 - accuracy: 0.9491\n",
            "Epoch 32/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1378 - accuracy: 0.9439\n",
            "Epoch 33/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1278 - accuracy: 0.9439\n",
            "Epoch 34/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1207 - accuracy: 0.9526\n",
            "Epoch 35/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1149 - accuracy: 0.9439\n",
            "Epoch 36/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1145 - accuracy: 0.9439\n",
            "Epoch 37/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1107 - accuracy: 0.9491\n",
            "Epoch 38/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1139 - accuracy: 0.9509\n",
            "Epoch 39/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1166 - accuracy: 0.9456\n",
            "Epoch 40/40\n",
            "570/570 [==============================] - 2s 3ms/sample - loss: 0.1152 - accuracy: 0.9421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZidmnc-U79N"
      },
      "source": [
        "def plot_graphs(history, string, name_model):\n",
        "  title = \"Visualizzazione della curva di Training del modello \" + name_model\n",
        "  plt.suptitle(title)\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epoche\")\n",
        "  plt.ylabel(ylabel=\"Accuratezza\")\n",
        "  plt.show()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "tt-T68mJU98S",
        "outputId": "08055f90-6922-44cd-b99e-f1d4e0364b8b"
      },
      "source": [
        "plot_graphs(history_bidirectional, 'accuracy', \"bidirezionale\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfiDYGL-gxHo"
      },
      "source": [
        "def make_prediction(next_word_len, tokenizer, model, text_to_predict, j):\n",
        "\tfor _ in range(next_word_len):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([text_to_predict])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\ttext_to_predict += \"\" + output_word \n",
        "\t\tj += \"\" + output_word \n",
        "\t\tnew_sequence = \"\".join(j) #isolo la nuova sequenza generata\n",
        "\treturn new_sequence"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ienvjiiw8_"
      },
      "source": [
        "def make_upper(text, index):\n",
        "  s = \"\"\n",
        "  for i in text:\n",
        "    if i == \"a\":\n",
        "      s = \"A\"\n",
        "    if i == \"c\":\n",
        "      s = \"C\"\n",
        "    if i == \"g\":\n",
        "      s = \"G\"\n",
        "    if i == \"t\":\n",
        "      s = \"T\"\n",
        "    index += \"\" + s\n",
        "    text = \"\".join(index)\n",
        "  return text"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143wOQzGFQlL"
      },
      "source": [
        "## Predizione partendo da metà sequenza non sanificata appartenente al dataset di partenza utilizzato per il training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RvJrUsGH3nL",
        "outputId": "19a4062f-e95c-4a4e-f0d3-23bb296878ce"
      },
      "source": [
        "#predizione con metà sequenza esistente\n",
        "existing_dna_seq = dna_not_sanitized[1]\n",
        "half_seq_length = int(seq_length / 2)\n",
        "\n",
        "\n",
        "text_to_predict = existing_dna_seq[0:10]\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model_bidirectional, text_to_predict, increase_string)\n",
        "\n",
        "print(make_upper(new_sequence, \"\")) #concatenazione tra sequenza passata in input e la nuova generata"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CTGCTGCAGC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95KCZvvAHxdo",
        "outputId": "e5d2e211-ce7d-4a21-fb52-8fefd511857f"
      },
      "source": [
        "print(\"Dna not sanitized in pos 0:\" , dna_not_sanitized[1])\n",
        "print(\"Dna sanitized in pos 0:    \" ,dna_sanitized[1])\n",
        "print(vocab)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dna not sanitized in pos 0: TTGCCATGGACGCTGGTACT\n",
            "Dna sanitized in pos 0:     AGTCAGTCCGCTAGGTACGC\n",
            "{'t': 1, 'a': 2, 'g': 3, 'c': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybE9QpyqGCHM"
      },
      "source": [
        "##Predizione partendo da metà sequenza randomica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ONs5spxg1rp",
        "outputId": "7e076ce5-afeb-42b6-d59d-89053303c8e8"
      },
      "source": [
        "#genero metà sequenza di dna non sanificato\n",
        "half_seq_length = int(seq_length / 2)\n",
        "half_sequence = [random.choice(bases_list) for _ in range(half_seq_length)]\n",
        "half_sequence = \"\".join(half_sequence)\n",
        "\n",
        "print(half_sequence)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CCGACGAAAC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZx5OkTB-5_R",
        "outputId": "e7b759fc-6bfa-4e2b-fca8-ad716519fb3c"
      },
      "source": [
        "text_to_predict = half_sequence\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model_bidirectional, text_to_predict, increase_string)\n",
        "#new_sequence , text_to_predict = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "#print(text_to_predict) #concatenazione tra sequenza passata in input e la nuova generata\n",
        "print(make_upper(new_sequence,\"\"))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GATAGGCGAC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievTU1NIGin9"
      },
      "source": [
        "##Predizione di una sequenza costituita da 440 caratteri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbyPwmy2ac9"
      },
      "source": [
        " Come si procede? Si scompone la sequenza lunga 440 in 44 sottosequenze, ognuna lunga 10 caratteri (questo perchè il modello risulta accurato per la predizione di stringhe lunghe 10 caratteri); poi per ognuna si genera la sequenza sanificata; infine si costruisce la sequenza finale tenendo conto dell'ordine di partenza relativo alle sottosequenze.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scHVDYYgaVdv"
      },
      "source": [
        "rnd_max_len = 440\n",
        "sub_seq_len = 10\n",
        "n_sub_seq = 44\n",
        "not_sanitized_max = []\n",
        "sub_seq_data = []\n",
        "\n",
        "random_seq_generation(1, rnd_max_len, not_sanitized_max)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zECPPK0d-vLo"
      },
      "source": [
        "sequence = not_sanitized_max[0]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqFPcbb_BOG"
      },
      "source": [
        "#grazie a questa funzione si riesce a dividere l'intera sequenza di lunghezza 440 in 44 sottosequenze, ognuna di 10 caratteri; si crea, quindi, una lista di sottosequenza\n",
        "def sub_seq_data_generator(entire_sequence, sub_len, n_sub_seq):\n",
        "  for i in range(n_sub_seq):\n",
        "    sub_seq = entire_sequence[i*sub_len:(i+1)*sub_len]\n",
        "    sub_seq_data.append(sub_seq)\n",
        "\n",
        "  return sub_seq_data"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_b6VhjCFHd"
      },
      "source": [
        "sub_seq_data = sub_seq_data_generator(sequence, sub_seq_len, n_sub_seq)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5g6QXOHkWx"
      },
      "source": [
        "new_sequence = make_prediction(next_words, tokenizer, model_bidirectional, text_to_predict, increase_string)\n",
        "sanitized_sub_seq_data = []\n",
        "increase_sequence = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_sub_seq_data.append(make_prediction(next_words, tokenizer, model_bidirectional, sub_seq_data[i], increase_sequence))"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgITChfEO9Jm"
      },
      "source": [
        "sanitized_max = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_max += sanitized_sub_seq_data[i]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqaslNI_1ww7",
        "outputId": "443782fa-4bbb-4e40-e644-9c8687d52ba1"
      },
      "source": [
        "print(\"Sequenza sanificata    : \" , make_upper(sanitized_max, \"\"))\n",
        "print(\"Sequenza non sanificata: \" , sequence)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequenza sanificata    :  CAAGTCAGTCTGTGTGTCGAGTGCATATTCCGACCGACGCGTGTGTGTATTTTTTTGGTCGAGTGTGTGCCATGAATGTCATGAGTGAAACATGTGCATAGCTGTGTGTAACAAGTCCCCGGGGGGGCAAAAAGTCGGTAAGTCCGTCCGATGAGTGCATCAATTTCTCGGCTCCGTTCCCCTCGTTCCCGGCAAGTGTCCGCTATGCAACTTTGCTTTGTCAATACGCAATGTGTGCATAGCATGATGAAAGTGTGTAATTTCAAAAGGTCTATTTGCTCGCCGGTGTCACATACGTCAAAGTCGGCGATCCGGGGCGATATTTTTAGTTAATTTTTCAGGCCCGTCCGCGCCGGGGGCCAAGTCCGAACCGTCGCGCGGCGCCGGTCCCACGTGTCCGGCTGTGTGTATAATTTTTAAGCGAGAGTGTCTCGGCGGCC\n",
            "Sequenza non sanificata:  TAAATTGAAAAGTATCTGCGGGTCGAGTGTTTGCTGGATCCCTGACGCTTTAACCCCCATTCGATGGTCCGCACTTTGCGCTAGCGTAGCAGTAATGTGGCTACCGTAGCCAGTCCGCAGGCCGACGCGGGTGGAGCATGCTCGGAAACCCGCTGTGAGCATTTCTCTTTAATATTTATGTCACAAGCCGGATGCGTTTGACGATGCTCGCTGATTTTTGTGCTGGCCAACCGCAGATGCAATCTGAATGGCTTAATGACTTCAAACTCACGTGGACTAAGAACGGTCTGAGAACGCTGCAGGAATCGTTGAGGAGCAGATGGGGTAATCAAAGTTTCATAACAGCAGTAGAACGTTCGGACTTCAGGGACAATGTAGGTAATACTTGTGATTTCGCCGACGCCCGTTACACTTGGTGGTTGAAATGTAGTAAATTATGT\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}