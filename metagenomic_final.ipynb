{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metagenomic_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RRdnF-T7GW3A",
        "SsYlsw4_Gbcc",
        "143wOQzGFQlL"
      ],
      "authorship_tag": "ABX9TyOaRpMB+e7z83HE2PSh6UW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xelanac/metagenomic_project/blob/main/metagenomic_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AruxVWPFnO"
      },
      "source": [
        "#Import delle librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDP2iYK4O-X6"
      },
      "source": [
        "%%capture\n",
        "!pip3 install google-nucleus==0.4.0\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#librerie per la lettura dei file fastq\n",
        "from nucleus.io import fastq\n",
        "from nucleus.io import fasta\n",
        "from nucleus.io import sam\n",
        "from nucleus.io import vcf\n",
        "from nucleus.io.genomics_writer import TFRecordWriter\n",
        "from nucleus.protos import reads_pb2\n",
        "from nucleus.util import cigar\n",
        "from nucleus.util import ranges\n",
        "from nucleus.util import utils\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#matplotlib per il plot dell'accuratezza del modello in base ad ogni epoca\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#librerie per la creazione del vocabolario\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#librerie per la costruzione della rete neurale RNN\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98V_jRj4PROA"
      },
      "source": [
        "#Generazione di dataset randomici"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDVaV9F9PVRs"
      },
      "source": [
        "bases_list = [\"A\",\"C\",\"G\",\"T\"]\n",
        "seq_length = 20 #lunghezza stringa\n",
        "seq_num = 20 #lunghezza dataset\n",
        "\n",
        "dna_not_sanitized = []\n",
        "dna_sanitized = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETl6UmH-CDh"
      },
      "source": [
        "def random_seq_generation(n_seq, seq_len, dataset):\n",
        "  for index in range(n_seq):\n",
        "    sequence = [random.choice(bases_list) for _ in range(seq_len)]\n",
        "    sequence = \"\".join(sequence)\n",
        "    dataset.append(sequence)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwW6If7-lQL"
      },
      "source": [
        "random_seq_generation(seq_num, seq_length, dna_not_sanitized)\n",
        "random_seq_generation(seq_num, seq_length, dna_sanitized)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJvyYzMpeZZ"
      },
      "source": [
        "#Caricamento e analisi di dati reali (in questo caso trascurare la precedente sezione di generazione di dataset randomici)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGydAYSlqKNs"
      },
      "source": [
        "Collegamento al drive e import dei dati reali"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhdq0_cqA6n"
      },
      "source": [
        "#accesso al drive\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\" \n",
        "# Leggo il file grezzo fastq\n",
        "input_path_not_sanitized = \"/content/drive/My Drive/fastQ_data/T0-R2-U1.R1.fastq\"\n",
        "input_path_sanitized = \"/content/drive/My Drive/fastQ_data/T0-R2-U3.R1.fastq\"\n",
        "\n",
        "fastq_data_not_sanitized = fastq.FastqReader(input_path_not_sanitized)\n",
        "fastq_data_sanitized = fastq.FastqReader(input_path_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1lKWqV6qaRT"
      },
      "source": [
        "Visualizzazione del fastQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHUIOCoxqUpy"
      },
      "source": [
        "def read_fastq_structure(dataset):\n",
        "  for i in dataset:\n",
        "    print(i)\n",
        "    break;\n",
        "\n",
        "print(\"Dataset campionato prima dell'azione danificante: \" , read_fastq_structure(dna_not_sanitized , \"\\n\"))\n",
        "print(\"Dataset campionato dopo l'azione danificante: \", read_fastq_structure(dna_sanitized, \"\\n\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOIOfifdrOl5"
      },
      "source": [
        "Funzione per l'isolamento delle sequenze\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgKzZ5nrQ-i"
      },
      "source": [
        "# Definisco un metodo per la lettura di un record della libreria FASTQ\n",
        "# Eventualmente rivediamo il metodo ora lo prendo per buono ma c'è qualcosa che non va\n",
        "# Se lo lanci due volte sfalsa l'output\n",
        "\n",
        "def seq_isolation(fastq_data, seq_list, single_record):\n",
        "    seq_list.append(single_record)\n",
        "    single_sequence = str(seq_list[0])\n",
        "    single_record_list = single_sequence.split(\"\\n\") #lista contenente le proprietà di una singola sequenza(id, sequence, quality)\n",
        "\n",
        "    fastq_sequence = single_record_list[2].split(\" \") #2 è la posizione della sequenza\n",
        "    final_sequence = fastq_sequence[1] #posizione nella nuova lista\n",
        "    new_sequence = \"\"\n",
        "\n",
        "    for i in final_sequence: #tolgo le \"\" dalla stringa\n",
        "      if i != '\"':\n",
        "        new_sequence += i\n",
        "\n",
        "    final_sequence = new_sequence\n",
        "    #print(final_sequence)\n",
        "    return final_sequence  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkpu9Fl0rbqM"
      },
      "source": [
        "**Inizio dell'analisi dei dati**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz7_pO84rdkW"
      },
      "source": [
        "# Creo due liste contenenti rispettivamente le sequenze del dna campionate prima e dopo l'azione sanificante\n",
        "fastq_data_list = []\n",
        "dna_not_sanitized = []\n",
        "dna_sanitized = []\n",
        "\n",
        "for index in fastq_data_not_sanitized:\n",
        "  dna_not_sanitized.append(seq_isolation(fastq_data_not_sanitized, fastq_data_list, index))\n",
        "\n",
        "fastq_data_list = []\n",
        "\n",
        "for index in fastq_data_sanitized:\n",
        "  dna_not_sanitized.append(seq_isolation(fastq_data_not_sanitized, fastq_data_list, index))\n",
        "\n",
        "# Stampo il numero di sequenze del dataset \"not_sanitized\"\n",
        "len(dna_not_sanitized)\n",
        "# Stampo il numero di sequenze del dataset \"sanitized\"\n",
        "len(dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt9FrIPEsXsf"
      },
      "source": [
        "Check sulla lunghezza delle sequenze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKNr1LGxsZ4Z"
      },
      "source": [
        "#Lunghezza massima e minima del dataset \"not_sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_not_sanitized: \" , len(max(dna_not_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_not_sanitized: \" , len(min(dna_not_sanitized, key=len)), \"\\n\")\n",
        "\n",
        "#Lunghezza massima e minima del dataset \"sanitized\"\n",
        "print(\"Lunghezza massima delle sequenze dna_sanitized: \" ,  len(max(dna_sanitized, key=len)))\n",
        "print(\"Lunghezza minima delle sequenze dna_sanitized: \" , len(min(dna_sanitized, key=len)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nm26iWyti0e"
      },
      "source": [
        "Check che verifica se la sequenza ha qualche parametro \"K\", il quale indica un'imprecisione in fase di campionamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jSNcbOtr8H"
      },
      "source": [
        "def sequences_check(sequences_list):\n",
        "  i = 0\n",
        "\n",
        "  for single_sequence in sequences_list:\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        return True\n",
        "    i+= 1\n",
        "  return False\n",
        "  \n",
        "print(\"Check delle sequenze non sanificate: \\n\", sequence_check(dna_not_sanitized))\n",
        "print(\"Check delle sequenze  sanificate: \\n\", sequence_check(dna_sanitized))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fee-J8Hv6Xl"
      },
      "source": [
        "Se la funzione \"sequence_check()\" restituisce \"True\" per una delle due liste, procedere con la correzione; altrimenti procedere con la creazione del vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA9OYhpBwKxS"
      },
      "source": [
        "#con questo metodo sostituisco il parametro \"k\" con una delle basi azotate(in questo caso ho scelto l'Adenina)\n",
        "def sequences_correction(sequences_list): \n",
        "  j = 0\n",
        "  new_dna_sequence_list = []\n",
        "  for single_sequence in sequences_list:\n",
        "    i = 0\n",
        "    new_sequence = \"\"\n",
        "    for index in single_sequence:\n",
        "      if index == \"K\":\n",
        "        new_sequence+=\"A\"\n",
        "      else:\n",
        "        new_sequence+=index\n",
        "      i+=1\n",
        "    new_dna_sequence_list.append(new_sequence)  \n",
        "    j+=1     \n",
        "\n",
        "  sequences_list = new_dna_sequence_list\n",
        "  return sequences_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXACHaqy05hm"
      },
      "source": [
        "sequences_correction(dna_not_sanitized)\n",
        "sequences_correction(dna_sanitized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJqAwxPCSsio"
      },
      "source": [
        "#Creo il vocabolario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqTGuXyUac1t",
        "outputId": "44475e52-09c9-49ed-e788-4ec01de15fe7"
      },
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "\n",
        "tokenizer.fit_on_texts(dna_not_sanitized)\n",
        "\n",
        "vocab = tokenizer.word_index\n",
        "vocab_length = len(vocab) + 1\n",
        "\n",
        "print(\"Vocabulary: \" ,vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary:  {'t': 1, 'a': 2, 'g': 3, 'c': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5uXy2ogTC5s"
      },
      "source": [
        "input_not_sanitized = []\n",
        "\n",
        "for record in dna_not_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([record])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_not_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_not_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_not_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "#xs, labels_x = input_sequences[:,:-1],input_sequences[:,-1] #il -1 omette l'ultimo carattere\n",
        "xs = input_sequences[:,:-1] #il -1 omette l'ultimo carattere"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXv9sV36kk6E",
        "outputId": "e76ed7c9-a63c-44d0-a406-e12a7f4fd6f5"
      },
      "source": [
        "print(input_sequences)\n",
        "print(input_sequences[:-1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 2 4]\n",
            " [0 0 0 ... 2 4 1]\n",
            " [0 0 0 ... 4 1 3]\n",
            " ...\n",
            " [0 0 3 ... 2 3 2]\n",
            " [0 3 2 ... 3 2 3]\n",
            " [3 2 3 ... 2 3 3]]\n",
            "[[0 0 0 ... 0 2 4]\n",
            " [0 0 0 ... 2 4 1]\n",
            " [0 0 0 ... 4 1 3]\n",
            " ...\n",
            " [0 0 0 ... 4 2 3]\n",
            " [0 0 3 ... 2 3 2]\n",
            " [0 3 2 ... 3 2 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWSt4TxlUYDG"
      },
      "source": [
        "input_sanitized = []\n",
        "\n",
        "for line in dna_sanitized:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sanitized.append(n_gram_sequence)\n",
        "\n",
        "#pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sanitized])\n",
        "input_sequences = np.array(pad_sequences(input_sanitized, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "ys, labels_y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels_y, num_classes=vocab_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnTRmRr_Usus"
      },
      "source": [
        "#Costruzione del modello Rnn con layer LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdnF-T7GW3A"
      },
      "source": [
        "##Modello RNN Bidirezionale(LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnKFEBGnK7MP"
      },
      "source": [
        "**N.B:** Bidirectional fa una copia del layer RNN passatogli come argomento e, attraverso il campo go_backwards, riesce a capovolgere l'input, quindi ad elaborarlo anche in ordine inverso.\n",
        "Questo apporccio non tiene conto solo delle parole successive da generare, ma anche del contesto che c'è intorno al carattere/parola successiva al fine di ottere una migliore predizione, preservando più informazioni utili nel tempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPaav9HU1U-"
      },
      "source": [
        "model = Sequential(name=\"metagenomic prediction\")\n",
        "model.add(Embedding(vocab_length, 110, input_length=max_sequence_len-1, name=\"input_layer\"))\n",
        "model.add(Bidirectional(LSTM(150), name=\"LSTM\"))\n",
        "model.add(Dense(vocab_length, activation='softmax', name=\"last_layer\"))\n",
        "\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dop7BAANU21P",
        "outputId": "922ef1ca-a414-4d7a-bd1a-bb5e0661880d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"metagenomic prediction\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Embedding)      (None, 19, 110)           550       \n",
            "_________________________________________________________________\n",
            "LSTM (Bidirectional)         (None, 300)               313200    \n",
            "_________________________________________________________________\n",
            "last_layer (Dense)           (None, 5)                 1505      \n",
            "=================================================================\n",
            "Total params: 315,255\n",
            "Trainable params: 315,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsYlsw4_Gbcc"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpqqVH6U4mG",
        "outputId": "9a4ceb80-94e1-4b68-a42f-3e680d206223"
      },
      "source": [
        "history = model.fit(xs, ys, epochs=40, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "380/380 [==============================] - 1s 4ms/sample - loss: 1.5308 - accuracy: 0.2526\n",
            "Epoch 2/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.4165 - accuracy: 0.2263\n",
            "Epoch 3/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.4044 - accuracy: 0.2526\n",
            "Epoch 4/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.3769 - accuracy: 0.3026\n",
            "Epoch 5/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.3737 - accuracy: 0.3184\n",
            "Epoch 6/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.3627 - accuracy: 0.3447\n",
            "Epoch 7/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.3397 - accuracy: 0.3500\n",
            "Epoch 8/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.3068 - accuracy: 0.4158\n",
            "Epoch 9/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.2686 - accuracy: 0.4053\n",
            "Epoch 10/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 1.1994 - accuracy: 0.4684\n",
            "Epoch 11/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 1.0850 - accuracy: 0.5553\n",
            "Epoch 12/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.9224 - accuracy: 0.5895\n",
            "Epoch 13/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.7567 - accuracy: 0.7079\n",
            "Epoch 14/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.5426 - accuracy: 0.7947\n",
            "Epoch 15/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.3863 - accuracy: 0.8684\n",
            "Epoch 16/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.2545 - accuracy: 0.9132\n",
            "Epoch 17/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1870 - accuracy: 0.9421\n",
            "Epoch 18/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1443 - accuracy: 0.9474\n",
            "Epoch 19/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1269 - accuracy: 0.9474\n",
            "Epoch 20/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1164 - accuracy: 0.9500\n",
            "Epoch 21/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1112 - accuracy: 0.9500\n",
            "Epoch 22/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1023 - accuracy: 0.9447\n",
            "Epoch 23/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1079 - accuracy: 0.9368\n",
            "Epoch 24/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1035 - accuracy: 0.9500\n",
            "Epoch 25/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1025 - accuracy: 0.9474\n",
            "Epoch 26/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1113 - accuracy: 0.9526\n",
            "Epoch 27/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1061 - accuracy: 0.9447\n",
            "Epoch 28/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.0964 - accuracy: 0.9421\n",
            "Epoch 29/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1066 - accuracy: 0.9421\n",
            "Epoch 30/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1086 - accuracy: 0.9421\n",
            "Epoch 31/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0998 - accuracy: 0.9526\n",
            "Epoch 32/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.0965 - accuracy: 0.9526\n",
            "Epoch 33/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.0972 - accuracy: 0.9474\n",
            "Epoch 34/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.1009 - accuracy: 0.9447\n",
            "Epoch 35/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0990 - accuracy: 0.9500\n",
            "Epoch 36/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.1018 - accuracy: 0.9395\n",
            "Epoch 37/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0997 - accuracy: 0.9500\n",
            "Epoch 38/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.0989 - accuracy: 0.9553\n",
            "Epoch 39/40\n",
            "380/380 [==============================] - 1s 3ms/sample - loss: 0.0972 - accuracy: 0.9447\n",
            "Epoch 40/40\n",
            "380/380 [==============================] - 1s 2ms/sample - loss: 0.0966 - accuracy: 0.9526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZidmnc-U79N"
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epoche\")\n",
        "  plt.ylabel(ylabel=\"Accuratezza\")\n",
        "  plt.show()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tt-T68mJU98S",
        "outputId": "848e7e4e-82d8-4374-a27d-cf5e120210dd"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfiDYGL-gxHo"
      },
      "source": [
        "def make_prediction(next_word_len, tokenizer, model, text_to_predict, j):\n",
        "\tfor _ in range(next_word_len):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([text_to_predict])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\ttext_to_predict += \"\" + output_word \n",
        "\t\tj += \"\" + output_word \n",
        "\t\tnew_sequence = \"\".join(j) #isolo la nuova sequenza generata\n",
        "\treturn new_sequence"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143wOQzGFQlL"
      },
      "source": [
        "## Predizione partendo da metà sequenza non sanificata appartenente al dataset di partenza utilizzato per il training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RvJrUsGH3nL",
        "outputId": "119e05c1-c915-49a8-e4c5-2f7cd9717a8b"
      },
      "source": [
        "#predizione con metà sequenza esistente\n",
        "existing_dna_seq = dna_not_sanitized[1]\n",
        "half_seq_length = int(seq_length / 2)\n",
        "\n",
        "\n",
        "text_to_predict = existing_dna_seq[0:10]\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "print(new_sequence) #concatenazione tra sequenza passata in input e la nuova generata"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gctcgaaccg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95KCZvvAHxdo",
        "outputId": "a9e8b4a6-fe9e-4f9d-c130-60525f40544e"
      },
      "source": [
        "print(\"Dna not sanitized in pos 0:\" , dna_not_sanitized[1])\n",
        "print(\"Dna sanitized in pos 0:    \" ,dna_sanitized[1])\n",
        "print(vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dna not sanitized in pos 0: AAGGTTGCTACATTGGGGGC\n",
            "Dna sanitized in pos 0:     TCCAAAATCAGTACTAACGG\n",
            "{'t': 1, 'a': 2, 'g': 3, 'c': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybE9QpyqGCHM"
      },
      "source": [
        "##Predizione partendo da metà sequenza randomica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ONs5spxg1rp",
        "outputId": "7cc40fa5-83eb-417f-9710-43f712257bae"
      },
      "source": [
        "#genero metà sequenza di dna non sanificato\n",
        "half_seq_length = int(seq_length / 2)\n",
        "half_sequence = [random.choice(bases_list) for _ in range(half_seq_length)]\n",
        "half_sequence = \"\".join(half_sequence)\n",
        "\n",
        "print(half_sequence)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AATATATCCA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZx5OkTB-5_R",
        "outputId": "f86b3160-39fd-4cdb-c731-fbd4d6d2ce22"
      },
      "source": [
        "text_to_predict = half_sequence\n",
        "next_words = half_seq_length\n",
        "new_sequence = []\n",
        "increase_string = \"\"\n",
        "\n",
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "#new_sequence , text_to_predict = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "\n",
        "#print(text_to_predict) #concatenazione tra sequenza passata in input e la nuova generata\n",
        "print(new_sequence)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gatcctgcca\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ienvjiiw8_"
      },
      "source": [
        "def make_upper(text, index):\n",
        "  s = \"\"\n",
        "  for i in text:\n",
        "    if i == \"a\":\n",
        "      s = \"A\"\n",
        "    if i == \"c\":\n",
        "      s = \"C\"\n",
        "    if i == \"g\":\n",
        "      s = \"G\"\n",
        "    if i == \"t\":\n",
        "      s = \"T\"\n",
        "    index += \"\" + s\n",
        "    text = \"\".join(index)\n",
        "  return text"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmnP9ZmvsYTq",
        "outputId": "896cb717-c678-4bc6-c9e5-cd441e379376"
      },
      "source": [
        "increase_sequence = \"\"\n",
        "print(make_upper(new_sequence, increase_sequence))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GATCCTGCCA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievTU1NIGin9"
      },
      "source": [
        "##Predizione di una sequenza costituita da 440 caratteri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbyPwmy2ac9"
      },
      "source": [
        " Come si procede? Si scompone la sequenza lunga 440 in 44 sottosequenze, ognuna lunga 10 caratteri (questo perchè il modello risulta accurato per la predizione di stringhe lunghe 10 caratteri); poi per ognuna si genera la sequenza sanificata; infine si costruisce la sequenza finale tenendo conto dell'ordine di partenza relativo alle sottosequenze.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scHVDYYgaVdv"
      },
      "source": [
        "rnd_max_len = 440\n",
        "sub_seq_len = 10\n",
        "n_sub_seq = 44\n",
        "not_sanitized_max = []\n",
        "sub_seq_data = []\n",
        "\n",
        "random_seq_generation(1, rnd_max_len, not_sanitized_max)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zECPPK0d-vLo"
      },
      "source": [
        "sequence = not_sanitized_max[0]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqFPcbb_BOG"
      },
      "source": [
        "#grazie a questa funzione si riesce a dividere l'intera sequenza di lunghezza 440 in 44 sottosequenze, ognuna di 10 caratteri; si crea, quindi, una lista di sottosequenza\n",
        "def sub_seq_data_generator(entire_sequence, sub_len, n_sub_seq):\n",
        "  for i in range(n_sub_seq):\n",
        "    sub_seq = entire_sequence[i*sub_len:(i+1)*sub_len]\n",
        "    sub_seq_data.append(sub_seq)\n",
        "\n",
        "  return sub_seq_data"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_b6VhjCFHd"
      },
      "source": [
        "sub_seq_data = sub_seq_data_generator(sequence, sub_seq_len, n_sub_seq)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5g6QXOHkWx"
      },
      "source": [
        "new_sequence = make_prediction(next_words, tokenizer, model, text_to_predict, increase_string)\n",
        "sanitized_sub_seq_data = []\n",
        "increase_sequence = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_sub_seq_data.append(make_prediction(next_words, tokenizer, model, sub_seq_data[i], increase_sequence))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgITChfEO9Jm"
      },
      "source": [
        "sanitized_max = \"\"\n",
        "\n",
        "for i in range(n_sub_seq):\n",
        "  sanitized_max += sanitized_sub_seq_data[i]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqaslNI_1ww7",
        "outputId": "5f6a5e15-686b-4b35-9c1d-33bd749f9aff"
      },
      "source": [
        "print(\"Sequenza sanificata    : \" , make_upper(sanitized_max, \"\"))\n",
        "print(\"Sequenza non sanificata: \" , sequence)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequenza sanificata    :  GCTGCCAACCGATCCGATCTATTTAGTGGCGGGGGGGCCGCCGATCTGAGGTAGGTTGGCGATTTCCCGATTCTGATCCGCAATTCTTGTCTGCCGATCTTTCGATCCAACGTTTGGTTGTTCCCGATTTATTTTTCCCCGCTGCCAACCGCCGCCGATTGGCCGGCTGGGATTGCCGGCCTCGATCCGCTGCATGCTCGCCTGCCATCCGAGCCTGCCGAGTTCCCCCCTGCCGATAGCTGGGGGGGTGCCCGATTTCAGTCGATCCTGGCCTCCCGATGATCTGAGCTCCGAATTTTGATGCCGATTTGCCCAAAATCCCGATTGCTGGATCCGATTATCCTGTTTCCCCAACCAAAATCGCCATCCGCCCCCCCCCCCCAACCTCGATCCCGATATGTGCCCCCCCCCCCAAATGCTGTTATGCCGTGGGGGGGGTG\n",
            "Sequenza non sanificata:  TATTGATATAAGCTAATGTCTCCTACAGTGCACGATGGGGATTTCGGCTGCATCCGATCTCTCGCATACCGGTCTCCCATGTTGGACCACGTCCCTCTGTGCATTATTAGTATCATATTTCGTGCAGGTACGCACGGGCCATGATGGAGACTAGGATAGTTTTGCTGGTGATACATGGGCGGCGCCAGTGTGCTACGACAATAGGAGTAGGTTACAAGAGGAGCATTTGAGAATTCGTATTCCCTGTTATCACTTCAAGCTGGCTCTATATAACTTCCTTACCCTGTTGCCTCCTGATACCCCAGCAGGCGGATTTATAACAGCCTCACACCATGACCGCCTGACTACAAATTTGAAAAAGATGTTCGGAGGCACTGGCCATTGATGCTGAGAATGCTTTGCGTAAGTGCGTAGCGTATCCTGCAACTCAACCATTGAGG\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}